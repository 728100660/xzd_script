# web socketå®æ—¶é€šè¯
# pip install fastapi uvicorn
import asyncio
import numpy as np
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from funasr import AutoModel
import base64
import json
import uvicorn
import torch
from silero_vad import load_silero_vad, VADIterator
import time

app = FastAPI()

# === åˆå§‹åŒ– FunASR æµå¼æ¨¡å‹ ===
chunk_size = [0, 10, 5]
encoder_chunk_look_back = 4
decoder_chunk_look_back = 1

model = AutoModel(model="paraformer-zh-streaming")
print("âœ… FunASR æ¨¡å‹åŠ è½½å®Œæˆ")

# === åˆå§‹åŒ– Silero VAD ===
# å°è¯•åŠ è½½æ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™æç¤ºå®‰è£…
try:
    torch_model, utils = load_silero_vad()
    get_speech_timestamps = utils[0]
    print("âœ… Silero VAD æ¨¡å‹åŠ è½½å®Œæˆ")
except Exception as e:
    print(f"âŒ Silero VAD åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿å·²å®‰è£…: pip install silero-vad\né”™è¯¯ä¿¡æ¯: {e}")
    # è¿™é‡Œå¯ä»¥é€‰æ‹©é€€å‡ºæˆ–é™çº§åˆ°å…¶ä»–VADæ–¹æ¡ˆ
    raise

# å­˜å‚¨æ¯ä¸ªä¼šè¯çš„ä¸Šä¸‹æ–‡ç¼“å­˜
session_cache = {}


class SessionVADManager:
    """ç®¡ç†ä¼šè¯çš„VADçŠ¶æ€"""

    def __init__(self, sampling_rate=16000):
        self.vad_iterator = VADIterator(
            model=torch_model,
            threshold=0.5,  # è¯­éŸ³æ¦‚ç‡é˜ˆå€¼ï¼Œå¯æ ¹æ®ç¯å¢ƒè°ƒæ•´[citation:10]
            sampling_rate=sampling_rate,
            min_silence_duration_ms=100,  # æœ€å°é™éŸ³æ—¶é•¿[citation:10]
            speech_pad_ms=30  # è¯­éŸ³ç‰‡æ®µå‰åå¡«å……[citation:10]
        )
        self.sampling_rate = sampling_rate
        self.is_speaking = False
        self.last_voice_time = 0
        self.speech_timeout = 1.5  # è¯­éŸ³ç»“æŸè¶…æ—¶ï¼ˆç§’ï¼‰

    def process_audio(self, audio_chunk):
        """å¤„ç†éŸ³é¢‘å—ï¼Œè¿”å›VADçŠ¶æ€"""
        current_time = time.time()

        # ä½¿ç”¨VADIteratorå¤„ç†éŸ³é¢‘å—[citation:6]
        speech_dict = self.vad_iterator(audio_chunk, return_seconds=False)

        if speech_dict is not None:
            self.is_speaking = True
            self.last_voice_time = current_time
            return "speaking"
        else:
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if self.is_speaking and (current_time - self.last_voice_time) > self.speech_timeout:
                self.is_speaking = False
                return "speech_end"
            elif not self.is_speaking:
                return "silence"
            else:
                return "speaking"  # ä»åœ¨è¯´è¯ï¼Œæœªè¶…æ—¶

    def reset(self):
        """é‡ç½®VADçŠ¶æ€"""
        self.vad_iterator.reset_states()
        self.is_speaking = False
        self.last_voice_time = 0


class SentenceAccumulator:
    """æ™ºèƒ½å¥å­ç´¯ç§¯å™¨"""

    def __init__(self):
        self.current_sentence = ""
        self.last_add_time = 0
        self.sentence_timeout = 1.2  # å¥å­å®Œæˆè¶…æ—¶
        self.min_sentence_length = 3  # æœ€å°å¥å­é•¿åº¦

    def add_text(self, new_text, is_final=False):
        """æ·»åŠ æ–‡æœ¬å¹¶åˆ¤æ–­æ˜¯å¦å½¢æˆå®Œæ•´å¥å­"""
        if not new_text.strip():
            return None, False

        current_time = time.time()
        merged_text = self._merge_text(self.current_sentence, new_text)

        # æ›´æ–°å½“å‰å¥å­
        self.current_sentence = merged_text
        self.last_add_time = current_time

        # åˆ¤æ–­å¥å­ç»“æŸçš„æ¡ä»¶
        sentence_end = False
        send_text = None

        # æ¡ä»¶1: å¼ºåˆ¶ç»“æŸï¼ˆå¦‚VADæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼‰
        if is_final:
            send_text = self.current_sentence
            self.current_sentence = ""
            sentence_end = True

        # æ¡ä»¶2: æ£€æµ‹åˆ°è‡ªç„¶å¥å­ç»“æŸï¼ˆå¥å·ã€é—®å·ç­‰ï¼‰
        elif self._has_sentence_end(merged_text):
            send_text = self.current_sentence
            self.current_sentence = ""
            sentence_end = True

        # æ¡ä»¶3: è¶…æ—¶ä¸”æœ‰ä¸€å®šé•¿åº¦
        elif (current_time - self.last_add_time > self.sentence_timeout and
              len(merged_text) >= self.min_sentence_length):
            send_text = self.current_sentence
            self.current_sentence = ""
            sentence_end = True

        return send_text, sentence_end

    def _merge_text(self, old_text, new_text):
        """æ™ºèƒ½åˆå¹¶æ–‡æœ¬ï¼Œå»é™¤é‡å éƒ¨åˆ†"""
        if not old_text:
            return new_text

        # ç®€å•é‡å æ£€æµ‹ï¼šæ£€æŸ¥æ–°æ–‡æœ¬å¼€å¤´æ˜¯å¦ä¸æ—§æ–‡æœ¬ç»“å°¾é‡å¤
        overlap_len = min(len(old_text), len(new_text), 6)  # æ£€æŸ¥æœ€å¤š6ä¸ªå­—ç¬¦
        for i in range(overlap_len, 0, -1):
            if old_text.endswith(new_text[:i]):
                return old_text + new_text[i:]

        return old_text + new_text

    def _has_sentence_end(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å¥å­ç»“æŸæ ‡å¿—"""
        end_marks = ['ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!', 'ï¼Œ', ',']
        return any(text.endswith(mark) for mark in end_marks)

    def get_current_text(self):
        """è·å–å½“å‰ç´¯ç§¯çš„æ–‡æœ¬"""
        return self.current_sentence

    def reset(self):
        """é‡ç½®ç´¯ç§¯å™¨"""
        self.current_sentence = ""
        self.last_add_time = 0


@app.websocket("/ws/asr/{session_id}")
async def ws_asr(websocket: WebSocket, session_id: str):
    await websocket.accept()
    print(f"ğŸ§ æ–°ä¼šè¯: {session_id}")

    # åˆå§‹åŒ–ä¼šè¯ç»„ä»¶
    vad_manager = SessionVADManager(sampling_rate=16000)
    sentence_accumulator = SentenceAccumulator()

    session_cache[session_id] = {
        "cache": {},
        "buffer": np.array([], dtype=np.float32),
        "vad_manager": vad_manager,
        "sentence_accumulator": sentence_accumulator,
        "last_audio_time": time.time()
    }

    try:
        while True:
            try:
                message = await asyncio.wait_for(websocket.receive_text(), timeout=0.3)
            except asyncio.TimeoutError:
                # æ£€æŸ¥VADè¶…æ—¶
                session_data = session_cache[session_id]
                vad_manager = session_data["vad_manager"]

                # å¤„ç†VADè¶…æ—¶
                vad_result = vad_manager.process_audio(None)  # ä¼ å…¥Noneæ¥æ£€æŸ¥è¶…æ—¶
                if vad_result == "speech_end":
                    await _finalize_current_utterance(session_id, websocket)
                continue

            msg = json.loads(message)
            session_data = session_cache[session_id]
            session_data["last_audio_time"] = time.time()

            if msg["type"] == "audio":
                await _process_audio_data(session_id, websocket, msg["data"])

            elif msg["type"] == "end":
                await _finalize_session(session_id, websocket)
                break

    except WebSocketDisconnect:
        print(f"âŒ è¿æ¥æ–­å¼€: {session_id}")
    except Exception as e:
        print(f"âŒ å¤„ç†é”™è¯¯ {session_id}: {e}")
        await websocket.send_text(json.dumps({"type": "error", "data": str(e)}))
    finally:
        session_cache.pop(session_id, None)


async def _process_audio_data(session_id, websocket, audio_data):
    """å¤„ç†éŸ³é¢‘æ•°æ®"""
    session_data = session_cache[session_id]

    # è§£ç éŸ³é¢‘
    audio_bytes = base64.b64decode(audio_data)
    audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
    chunk = audio_int16.astype(np.float32) / 32768.0

    # ä½¿ç”¨Silero VADå¤„ç†[citation:6]
    vad_manager = session_data["vad_manager"]
    vad_result = vad_manager.process_audio(audio_int16)  # ä½¿ç”¨int16æ ¼å¼çš„éŸ³é¢‘

    # ç´¯ç§¯éŸ³é¢‘ç¼“å­˜
    buf = session_data["buffer"]
    buf = np.concatenate([buf, chunk])
    chunk_stride = chunk_size[1] * 960

    # å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘å—
    processed_count = 0
    while len(buf) >= chunk_stride and processed_count < 2:
        speech_chunk = buf[:chunk_stride]
        buf = buf[chunk_stride:]
        processed_count += 1

        # ASRè¯†åˆ«
        text = await _run_asr(session_id, speech_chunk, is_final=False)

        if text:
            # å‘é€å®æ—¶æ–‡æœ¬
            await websocket.send_text(json.dumps({
                "type": "interim_text",
                "data": text
            }))

            # ç´¯ç§¯åˆ°å¥å­ä¸­
            sentence_accumulator = session_data["sentence_accumulator"]
            complete_sentence, is_end = sentence_accumulator.add_text(text)

            if complete_sentence and is_end:
                print(f"ğŸ“ å®Œæ•´å¥å­: {complete_sentence}")
                await websocket.send_text(json.dumps({
                    "type": "sentence",
                    "data": complete_sentence
                }))

                # è¿™é‡Œå¯ä»¥æ·»åŠ å‘é€ç»™LLMçš„é€»è¾‘
                await _send_to_llm(websocket, complete_sentence)

    session_data["buffer"] = buf

    # å¦‚æœVADæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå¤„ç†å½“å‰è¯è¯­
    if vad_result == "speech_end":
        await _finalize_current_utterance(session_id, websocket)


async def _finalize_current_utterance(session_id, websocket):
    """ç»“æŸå½“å‰è¯è¯­"""
    session_data = session_cache[session_id]

    # å¤„ç†å‰©ä½™éŸ³é¢‘
    buf = session_data["buffer"]
    if len(buf) > 0:
        text = await _run_asr(session_id, buf, is_final=True)

        if text:
            await websocket.send_text(json.dumps({
                "type": "final_text",
                "data": text
            }))

            # å¼ºåˆ¶å®Œæˆå½“å‰å¥å­
            sentence_accumulator = session_data["sentence_accumulator"]
            complete_sentence, _ = sentence_accumulator.add_text(text, is_final=True)

            if not complete_sentence:
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°å®Œæ•´å¥å­ï¼Œä½†å½“å‰æœ‰ç´¯ç§¯æ–‡æœ¬ï¼Œä¹Ÿå‘é€
                current_text = sentence_accumulator.get_current_text()
                if current_text:
                    complete_sentence = current_text
                    sentence_accumulator.reset()

            if complete_sentence:
                print(f"ğŸš€ å‘é€ç»™LLM: {complete_sentence}")
                await websocket.send_text(json.dumps({
                    "type": "llm_ready",
                    "data": complete_sentence
                }))

    # é‡ç½®çŠ¶æ€
    session_data["buffer"] = np.array([], dtype=np.float32)
    session_data["vad_manager"].reset()


async def _run_asr(session_id, audio_chunk, is_final=False):
    """è¿è¡ŒASRè¯†åˆ«"""
    session_data = session_cache[session_id]
    cache = session_data["cache"]

    try:
        res = model.generate(
            input=audio_chunk,
            cache=cache,
            is_final=is_final,
            chunk_size=chunk_size,
            encoder_chunk_look_back=encoder_chunk_look_back,
            decoder_chunk_look_back=decoder_chunk_look_back,
        )

        # æ›´æ–°ç¼“å­˜
        if isinstance(res, dict) and "cache" in res:
            session_data["cache"] = res["cache"]

        # æå–æ–‡æœ¬
        if isinstance(res, list) and len(res) > 0:
            text = res[0].get("text", "")
        elif isinstance(res, dict):
            text = res.get("text", "")
        else:
            text = ""

        return text.strip()

    except Exception as e:
        print(f"ASRè¯†åˆ«é”™è¯¯: {e}")
        return ""


async def _send_to_llm(websocket, text):
    """å‘é€æ–‡æœ¬ç»™LLMï¼ˆè¿™é‡Œéœ€è¦ä½ å®ç°LLMé›†æˆï¼‰"""
    # è¿™é‡Œæ˜¯å‘é€ç»™LLMçš„å…¥å£ç‚¹
    # ä½ å¯ä»¥åœ¨è¿™é‡Œè°ƒç”¨ä½ çš„LLMæ¨¡å‹
    pass


async def _finalize_session(session_id, websocket):
    """ç»“æŸä¼šè¯"""
    await _finalize_current_utterance(session_id, websocket)
    await websocket.send_text(json.dumps({"type": "done"}))
    print(f"âœ… ä¼šè¯å®Œæˆ: {session_id}")


if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )